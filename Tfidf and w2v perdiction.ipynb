{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkUl9d12HGaG"
   },
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoYqnsOI9gP-",
    "outputId": "716a9c19-27ec-4443-fdfb-c937bc11a085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy-vQP5yHLqh"
   },
   "source": [
    "# READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "ejIJG128-dVX",
    "outputId": "6a45666a-1d49-4f8b-cecc-122bfc6f8717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://dataset-uploader/bbc/bbc-text.csv...\n",
      "/ [1 files][  4.8 MiB/  4.8 MiB]                                                \n",
      "Operation completed over 1 objects/4.8 MiB.                                      \n",
      "SHAPE OF DATASET:  (2225, 2) \n",
      "\n",
      "COLUMNS IN DATASET:  Index(['category', 'text'], dtype='object') \n",
      "\n",
      "CATEGORIES:  ['tech' 'business' 'sport' 'entertainment' 'politics'] \n",
      "\n",
      "DATA SAMPLE: \n",
      "\n",
      "            category                                               text\n",
      "813        business  us budget deficit to reach $368bn the us budge...\n",
      "1852  entertainment  surprise win for anti-bush film michael moore ...\n",
      "36             tech  gamers snap up new sony psp gamers have bought...\n",
      "1586           tech  apple ipod family expands market apple has exp...\n",
      "1530       business  ford gains from finance not cars ford  the us ... \n",
      "\n",
      "\n",
      "NUMBER OF SAMPLES IN EACH CATEGORY: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcd131a4080>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV50lEQVR4nO3de5gldX3n8fcHRjBR5OJMZpEBx0fJKomri/MoiolGIlEShRggapQRMaO7eIuXjckmBvLoE7ziLcGwogzGG6gIIjGSQVBRLjNyGYSoE5XALMjIzduqAb/7R/265kzTPfQMXX2amffrec7TVb+qOudb1af601V16ndSVUiSBLDDuAuQJM0fhoIkqWcoSJJ6hoIkqWcoSJJ6C8ZdwL2xcOHCWrp06bjLkKT7lDVr1vygqhZNNe0+HQpLly5l9erV4y5Dku5Tklw33TRPH0mSeoaCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSeoaCJKlnKEiSevfpO5o1M//xt48edwmzbp83rt2q5Q5874GzXMn4XfSKi8ZdgrYhgx4pJPlekrVJrkiyurXtkeS8JN9uP3dv7UnyniTrklyVZP8ha5Mk3d1cnD76nap6bFUta+NvAFZV1b7AqjYO8Exg3/ZYAZw0B7VJkkaM45rCocDKNrwSOGyk/bTqXAzslmTPMdQnSdutoUOhgC8kWZNkRWtbXFU3tuGbgMVteC/g+pFlb2htm0iyIsnqJKs3bNgwVN2StF0a+kLzk6tqfZJfA85L8m+jE6uqktSWPGFVnQycDLBs2bItWlaStHmDHilU1fr282bgTODxwPcnTgu1nze32dcDe48svqS1SZLmyGChkOQBSXaZGAYOBq4GzgaWt9mWA2e14bOBo9qnkA4A7hg5zSRJmgNDnj5aDJyZZOJ1PlpVn09yGXB6kmOA64Aj2/znAocA64CfAkcPWJskaQqDhUJVfQd4zBTttwAHTdFewLFD1SNJumd2cyFJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqTegnEXIEnj9r7XfnbcJcy6l7/jWVu1nEcKkqSeoSBJ6hkKkqTe4KGQZMcklyc5p40/LMklSdYl+USSnVr7zm18XZu+dOjaJEmbmosjhVcB146MvwU4saoeAdwGHNPajwFua+0ntvkkSXNo0E8fJVkC/D7wZuA1SQI8DXh+m2UlcBxwEnBoGwb4JPC+JKmq2prXftzrT9v6wuepNW87atwlSNrGDX2k8C7gfwG/bOMPBm6vqjvb+A3AXm14L+B6gDb9jjb/JpKsSLI6yeoNGzYMWbskbXcGC4UkfwDcXFVrZvN5q+rkqlpWVcsWLVo0m08tSdu9IU8fHQg8O8khwP2BBwHvBnZLsqAdDSwB1rf51wN7AzckWQDsCtwyYH2SpEkGO1Koqr+oqiVVtRR4LnB+Vf0J8EXg8DbbcuCsNnx2G6dNP39rrydIkrbOOO5T+HO6i87r6K4ZnNLaTwEe3NpfA7xhDLVJ0nZtTvo+qqoLgAva8HeAx08xz8+AI+aiHklw4W8/ZdwlzLqnfOnCcZdwn+cdzZKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKk3mChkOT+SS5NcmWSbyQ5vrU/LMklSdYl+USSnVr7zm18XZu+dKjaJElTG/JI4efA06rqMcBjgWckOQB4C3BiVT0CuA04ps1/DHBbaz+xzSdJmkODhUJ1ftxG79ceBTwN+GRrXwkc1oYPbeO06QclyVD1SZLubtBrCkl2THIFcDNwHvDvwO1VdWeb5QZgrza8F3A9QJt+B/DgKZ5zRZLVSVZv2LBhyPIlabszaChU1V1V9VhgCfB44JGz8JwnV9Wyqlq2aNGie12jJGmjGYVCklUzaZtOVd0OfBF4IrBbkgVt0hJgfRteD+zdnnsBsCtwy0xfQ5J07202FNoniPYAFibZPcke7bGUjad9plt2UZLd2vCvAE8HrqULh8PbbMuBs9rw2W2cNv38qqotXyVJ0tZacA/TXwq8GngIsAaYuPD7Q+B997DsnsDKJDvShc/pVXVOkmuAjyd5E3A5cEqb/xTgw0nWAbcCz93SlZEk3TubDYWqejfw7iSvqKr3bskTV9VVwH+fov07dNcXJrf/DDhiS15DkjS77ulIAYCqem+SJwFLR5epqtMGqkuSNAYzCoUkHwYeDlwB3NWaCzAUJGkbMqNQAJYB+3nhV5K2bTO9T+Fq4L8MWYgkafxmeqSwELgmyaV0fRoBUFXPHqQqSdJYzDQUjhuyCEnS/DDTTx9dOHQhkqTxm+mnj35E92kjgJ3oejz9SVU9aKjCJElzb6ZHCrtMDLfurA8FDhiqKEnSeGxxL6ntexI+A/zeAPVIksZopqePnjMyugPdfQs/G6QiSdLYzPTTR88aGb4T+B7dKSRJ0jZkptcUjh66EEnS+M30S3aWJDkzyc3t8akkS4YuTpI0t2Z6oflDdF+C85D2+GxrkyRtQ2YaCouq6kNVdWd7nAr4BcmStI2ZaSjckuQFSXZsjxfg9ydL0jZnpqHwYuBI4CbgRrrvUH7RQDVJksZkph9J/VtgeVXdBpBkD+DtdGEhSdpGzPRI4b9NBAJAVd3KFN+/LEm6b5tpKOyQZPeJkXakMNOjDEnSfcRM/7C/A/hakjPa+BHAm4cpSZI0LjO9o/m0JKuBp7Wm51TVNcOVJUkahxmfAmohYBBI0jZsi7vOliRtuwwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVJvsFBIsneSLya5Jsk3kryqte+R5Lwk324/d2/tSfKeJOuSXJVk/6FqkyRNbcgjhTuB11bVfsABwLFJ9gPeAKyqqn2BVW0c4JnAvu2xAjhpwNokSVMYLBSq6saq+nob/hFwLbAXcCiwss22EjisDR8KnFadi4Hdkuw5VH2SpLubk2sKSZbSff/CJcDiqrqxTboJWNyG9wKuH1nshtY2+blWJFmdZPWGDRsGq1mStkeDh0KSBwKfAl5dVT8cnVZVBdSWPF9VnVxVy6pq2aJFi2axUknSoKGQ5H50gfCRqvp0a/7+xGmh9vPm1r4e2Htk8SWtTZI0R4b89FGAU4Brq+qdI5POBpa34eXAWSPtR7VPIR0A3DFymkmSNAeG/ErNA4EXAmuTXNHa/hI4ATg9yTHAdcCRbdq5wCHAOuCnwNED1iZJmsJgoVBVXwEyzeSDppi/gGOHqkeSdM+8o1mS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1BssFJJ8MMnNSa4eadsjyXlJvt1+7t7ak+Q9SdYluSrJ/kPVJUma3pBHCqcCz5jU9gZgVVXtC6xq4wDPBPZtjxXASQPWJUmaxmChUFVfAm6d1HwosLINrwQOG2k/rToXA7sl2XOo2iRJU5vrawqLq+rGNnwTsLgN7wVcPzLfDa3tbpKsSLI6yeoNGzYMV6kkbYfGdqG5qgqorVju5KpaVlXLFi1aNEBlkrT9mutQ+P7EaaH28+bWvh7Ye2S+Ja1NkjSH5joUzgaWt+HlwFkj7Ue1TyEdANwxcppJkjRHFgz1xEk+BjwVWJjkBuBvgBOA05McA1wHHNlmPxc4BFgH/BQ4eqi6JEnTGywUqup500w6aIp5Czh2qFokSTPjHc2SpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqzatQSPKMJN9Msi7JG8ZdjyRtb+ZNKCTZEfh74JnAfsDzkuw33qokafsyb0IBeDywrqq+U1W/AD4OHDrmmiRpu5KqGncNACQ5HHhGVb2kjb8QeEJVvXzSfCuAFW30vwLfnNNCp7YQ+MG4i5gn3BYdt8NGbouN5su2eGhVLZpqwoK5ruTeqqqTgZPHXceoJKuratm465gP3BYdt8NGbouN7gvbYj6dPloP7D0yvqS1SZLmyHwKhcuAfZM8LMlOwHOBs8dckyRtV+bN6aOqujPJy4F/AXYEPlhV3xhzWTM1r05njZnbouN22MhtsdG83xbz5kKzJGn85tPpI0nSmBkKkqSeoTCNJLsl+Z9bueyp7b6LeS3J0iRX38vneEiST85WTduTJE9N8qRx1wGQ5LCt6UFgpuuQ5Nnj6rrm3uzLs/DaFyRZ1obPbbVsUs9824cMhentBozljXRfUlX/t6rmfQDON0kWAE8F5kUoAIfRdS8zY1uyDlV1dlWdsHWl3WvzYl+uqkOq6vbJ9cy7faiqfEzxoOtm4/8BVwBvA15P97HZq4DjR+Y7qrVdCXy4tZ0KvAf4KvAd4PBxr88067gU+DfgI8C1wCeBXwW+Byxs8ywDLmjDT2nb4wrgcmCX9hxXt+kvAj4NfB74NvDWkdc6GPga8HXgDOCBrf0E4Jq2Dd/e2o4Arm7b9Evj3k6tpgcAn2s1XQ38cdtObwXWApcCjxjZrue3dVoF7DPyvng/cEnbTjfR3YtzBfBbA9T8glbXFcA/0n2q78fAm9t6XAwspvujfivw3Tbvw9vj88Aa4MvAI2eyDsCz2rTLgX8FFo+8N963uf2DLmAuBM5q7ScAf9LWYS3w8DbfIuBTdPvjZcCBrf044IPABW35V061Lw+0zxzU1nltq2HnNv8FwLI2/D26O5on/21ZysZ9aEfg7XTvsauAV0y3nwz2Xh/3zjZfH5N+UQfTfZQsdEdX5wC/DfwG8C02/gHdY+RNf0abdz+6Pp3Gvk7TrGON7FQfBF7H9KHw2ZF5H0j3kebR7fSitjPuCtwfuI7uhsSFwJeAB7T5/hx4I/Bgum5KJj4Ft1v7uRbYa7Rt3A/gj4D/MzK+a9tO/7uNHwWcM7KdlrfhFwOfGXlfnAPs2MaPA143UL2PanXcr43/Q6uxgGe1trcCfzVS2+Ejy68C9m3DTwDOn8k6ALuP/D5fArxj5L0xGgp32z/oQuF2YE9gZ7qwOb5NexXwrjb8UeDJbXgf4NqRWr7all0I3ALcb/Q9OtA+81fA9cCvt7bTgFe34Qu4eyhsUg+b7kP/gy5oFrTxPZhmPxnqMW/uU5jnDm6Py9v4A4F9gccAZ1TVDwCq6taRZT5TVb8ErkmyeC6L3ULXV9VFbfifgFduZt6LgHcm+Qjw6aq6IcnkeVZV1R0ASa4BHkp3uLwfcFGbfye6o4Y7gJ8BpyQ5h+6PzcTrnJrkdLr/RueDtcA7kryF7o//l9u6fKxN/xhwYht+IvCcNvxhuj++E86oqrvmoN6DgMcBl7U6fwW4GfgFG7fzGuDpkxdM8kC6o4czRn6/O4/Msrl1WAJ8IsmedL/n704z33T7x2VVdWOr49+BL7T2tcDvtOHfBfYbqe1BrWaAz1XVz4GfJ7mZ7khotk3eZ/4a+G5Vfau1rQSOBd61Fc/9u8D7q+pO6P6mtNN0U+0ngzAUZibA31XVP27SmLxiM8v8fNLy89XkG1UKuJON15vu30+oOiHJ54BD6P7A/x7dm3XU6HrfRfceC3BeVT1v8osneTzdH7DDgZcDT6uqlyV5AvD7wJokj6uqW7Z2BWdDVX0ryf506/6mJKsmJo3ONoOn+smsFze1ACur6i82aUxeV+3fTTb+fibbAbi9qh47zXNvbh3eC7yzqs5O8lS6/96nMt3+Mdr+y5HxX47UugNwQFVt8t5rITHV+2+2Tf4930733/wgqrux9277yVCv54Xm6f2I7pw5dHdZv3jiv5EkeyX5NbrzxkckeXBr32Msld47+yR5Yht+PvAVusPcx7W2P5qYMcnDq2ptVb2F7lzuI2f4GhcDByZ5RHueByT59bY9d62qc4E/ozvymnidS6rqjcAGNu0TayySPAT4aVX9E9154P3bpD8e+fm1NvxVum5aoDsn/uVpnnb0PTbbVgGHt/cpSfZI8tDNzN/XUlU/BL6b5Ii2bJI85p6Wa3ZlY59ly+9F/ZvzBaD/hyzJdOE1Yba38+R9ZjWwdOL9DbyQ7trI1tRzHvDSdnQw8Xubcj8ZiqEwjfaf6UXtI5tPpzuP+bUka+nO+e1SXTccbwYuTHIl8M6xFbz1vgkcm+RauvPBJwHHA+9Ospruv60Jr05ydZKrgP8E/nkmL1BVG+jOKX+sLfs1ukDZBTintX0FeE1b5G1J1rZt/1W6i6Lj9mjg0iRXAH8DvKm1797qfxXdDgvdH6yjW/sL27SpfBb4wyRXJPmt2Sy2qq6hO9f9hVbHeXTn6qfzceD1SS5P8nC6MDumva+/wfTfbTJ5HY6jO+20huG6iH4lsCzJVe0U5cs2N/PovpzkbbPw+pP3mROBo+nWey3dUc37t7KeDwD/AVzVtv3zmX4/GYTdXEhbKcn36C4izof+8TUHkiylu6b0m2MuZTAeKUiSeh4pSJJ6HilIknqGgiSpZyhIknqGgrQF5lPPptIQDAVpyzyVgXs2bTeLuW9qLHzjSUCSo9rNUFcm+XCSZyW5pN3M9a9JFrfPqL8M+LOJm7WSLEryqSSXtceB7fkWJTkvyTeSfCDJdUkWtmmvaTcuXZ3k1a1taZJvJjmNrofMv07yrpH6/jTJiZPrlmabH0nVdi/JbwBnAk+qqh+07kqKrv+fSvIS4FFV9dokxwE/rqq3t2U/CvxDVX0lyT7Av1TVo5K8D1hfVX+X5Bl0d38vousg8FTgALo+fy6h6+L6NroeZp9UVRe3rg2upOuy+j+TfBV4aVWtnaPNou2UHeJJXedim/R2m+TRzKy3z+l67Hwy8Ift+T6f5LY2/cnAmVX1E4Akn6b7HoKzgeuq6uK2zI+TnA/8QetO4X4GguaCoSBNbaa9fW6ux84tNbn30Q8Af0n3pS4f2ponlLaU1xSkqXu7na63z8k9XE7XY+dFwJGt7WC6jtOg6zH1sCS/muQBdEcTU/aiWlWX0PUQ+3w2fm+DNChDQdu9aXq7PY6pe/uc3CvodD12Hg8c3Hp6PYLuayt/VFVfp7umcCnd9YQPVNXlTO904KKqum0z80izxgvN0gCS7Azc1b4g5YnASZv50prNPc85wIlVteoeZ5ZmgdcUpGHsA5ze7jf4BfCnW7Jwkt3ojiauNBA0lzxSkCT1vKYgSeoZCpKknqEgSeoZCpKknqEgSer9fzWaen2U/uX8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data frame\n",
    "!gsutil cp gs://dataset-uploader/bbc/bbc-text.csv .\n",
    "df = pd.read_csv('bbc-text.csv')\n",
    "\n",
    "# Description of the dataset\n",
    "print('SHAPE OF DATASET: ', df.shape, '\\n\\nCOLUMNS IN DATASET: ', df.columns, '\\n\\nCATEGORIES: ', df.category.unique(), '\\n\\nDATA SAMPLE: \\n\\n', df.sample(n=5), '\\n\\n')\n",
    "\n",
    "# Plotting number of samples within each category\n",
    "print('NUMBER OF SAMPLES IN EACH CATEGORY: \\n')\n",
    "sns.countplot(df.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8JavN4FHNn7"
   },
   "source": [
    "# CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22L7TrqYtFiz",
    "outputId": "a4bf7379-e2bd-41c1-f957-aa197fc8b6cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning in progress...\n",
      "Tokenization complete.\n",
      "Stop words removed.\n",
      "Numbers, punctuation and special characters removed.\n",
      "Lemmatization complete.\n",
      "Data cleaning complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DATA CLEANING\n",
    "print('Data cleaning in progress...')\n",
    "\n",
    "# Tokenize\n",
    "df['text_clean'] = df['text'].apply(nltk.word_tokenize)\n",
    "print('Tokenization complete.')\n",
    "\n",
    "# Remove stop words\n",
    "stop_words=set(nltk.corpus.stopwords.words(\"english\"))\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "print('Stop words removed.')\n",
    "\n",
    "# Remove numbers, punctuation and special characters (only keep words)\n",
    "regex = '[a-z]+'\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if re.match(regex, item)])\n",
    "print('Numbers, punctuation and special characters removed.')\n",
    "\n",
    "# Lemmatization\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\n",
    "print('Lemmatization complete.\\nData cleaning complete.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "394ApjV4HQfH"
   },
   "source": [
    "# 1 - WORD2VEC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QiqczAO5OHM0",
    "outputId": "2736c3c3-2540-4cac-fad2-b1da7d9e5fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :\n",
      "Accuracy: 0.387 \tPrecision: 0.408 \tRecall: 0.379 \t\tF1: 0.375\n",
      "\n",
      "SVC :\n",
      "Accuracy: 0.317 \tPrecision: 0.127 \tRecall: 0.291 \t\tF1: 0.177\n",
      "\n",
      "Decision Tree :\n",
      "Accuracy: 0.355 \tPrecision: 0.357 \tRecall: 0.356 \t\tF1: 0.355\n",
      "\n",
      "Perceptron :\n",
      "Accuracy: 0.321 \tPrecision: 0.135 \tRecall: 0.295 \t\tF1: 0.183\n",
      "\n",
      "Gradient Boosting :\n",
      "Accuracy: 0.443 \tPrecision: 0.443 \tRecall: 0.441 \t\tF1: 0.439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using word2vec vectorizer\n",
    "\n",
    "vec_model = Word2Vec(df['text_clean'])\n",
    "w2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))\n",
    "\n",
    "class Vectorizer(object):\n",
    "    \n",
    "    def __init__(self, vec):\n",
    "        self.vec = vec\n",
    "        self.dim = len(vec.values())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n",
    "\n",
    "class Classifier(object):\n",
    "    \n",
    "    def __init__(self, model, param):\n",
    "        self.model = model\n",
    "        self.param = param\n",
    "        self.gs = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)        \n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        return self.gs.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.gs.predict(X)\n",
    "\n",
    "clf_models = {\n",
    "    'Naive Bayes': GaussianNB(), \n",
    "    'SVC': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),  \n",
    "    'Perceptron': MLPClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "clf_params = {\n",
    "    'Naive Bayes': { }, \n",
    "    'SVC': { 'kernel': ['linear', 'rbf'] },\n",
    "    'Decision Tree': { 'min_samples_split': [2, 5] }, \n",
    "    'Perceptron': { 'activation': ['tanh', 'relu'] },\n",
    "    'Gradient Boosting': { 'min_samples_split': [2, 5] }\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
    "\n",
    "for key in clf_models.keys():\n",
    "    \n",
    "    clf = Pipeline([('Word2Vec vectorizer', Vectorizer(w2v)), ('Classifier', Classifier(clf_models[key], clf_params[key]))])\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(key, ':')\n",
    "    print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVlyG0i7LDwb"
   },
   "source": [
    "# 2-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTfHetcHmoaM",
    "outputId": "9951eb8b-949a-4b4a-eb9a-c80a31011604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete.\n",
      "\n",
      "Naive Bayes : {'alpha': 0.5, 'fit_prior': False}\n",
      "Precision: 0.973 \tRecall: 0.972 \t\tF1: 0.972\n",
      "\n",
      "Decision Tree : {'min_samples_split': 2}\n",
      "Precision: 0.783 \tRecall: 0.784 \t\tF1: 0.784\n",
      "\n",
      "Perceptron : {'activation': 'relu', 'alpha': 0.0001}\n",
      "Precision: 0.989 \tRecall: 0.990 \t\tF1: 0.990\n",
      "\n",
      "Gradient Boosting : {'learning_rate': 0.1, 'min_samples_split': 2}\n",
      "Precision: 0.963 \tRecall: 0.960 \t\tF1: 0.962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using TFIDF vectorizer\n",
    "\n",
    "# Vectorize training and testing data\n",
    "def Vectorize(vec, X_train, X_test):    \n",
    "    \n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    print('Vectorization complete.\\n')\n",
    "    \n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "# Use multiple classifiers and grid search for prediction\n",
    "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Precision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    return\n",
    "\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(), \n",
    "    'Decision Tree': DecisionTreeClassifier(),  \n",
    "    'Perceptron': MLPClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] }, \n",
    "    'Decision Tree': { 'min_samples_split': [1, 2, 5] }, \n",
    "    'Perceptron': { 'alpha': [0.0001, 0.001], 'activation': ['tanh', 'relu'] },\n",
    "    'Gradient Boosting': { 'learning_rate': [0.05, 0.1], 'min_samples_split': [2, 5] }\n",
    "}\n",
    "\n",
    "# Encode label categories to numbers\n",
    "enc = LabelEncoder()\n",
    "df['category'] = enc.fit_transform(df['category'])\n",
    "labels = list(enc.classes_)\n",
    "\n",
    "# Train-test split and vectorize\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
    "\n",
    "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of bbc-text-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
